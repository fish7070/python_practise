{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-3.5-turbo\", temperature=0):\n",
    "    '''\n",
    "    prompt: 对应的提示\n",
    "    model: 调用的模型，默认为 gpt-3.5-turbo(ChatGPT)，有内测资格的用户可以选择 gpt-4\n",
    "    temperature: 温度系数\n",
    "    '''\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]\n",
    "  \n",
    "def get_completion_from_messages(messages, model=\"gpt-3.5-turbo\", temperature=0):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature, # 控制模型输出的随机程度\n",
    "    )\n",
    "#     print(str(response.choices[0].message))\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neutral\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Classify the text into neutral, negative or positive.\n",
    "\n",
    "Text: I think the food was okay. \n",
    "Sentiment:\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neutral\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "\n",
    "Classify the text into neutral, negative or positive. \n",
    "\n",
    "Text: I think the vacation is okay.\n",
    "Sentiment: neutral \n",
    "Text: I think the food was okay. \n",
    "Sentiment:\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "這款鋼筆是一款經典而優雅的產品，設計簡潔而不失細節，完美地融合了現代與傳統的元素。它的筆身採用高品質的金屬材料，質感細膩，手感舒適，讓您在書寫時感受到極致的品質。筆尖採用精密的不銹鋼材料，經過嚴格的加工工藝，保證筆尖的耐用性和流暢度。此外，它還配備了一個方便的夾子，讓您可以輕鬆地將它固定在衣服或筆記本上，隨時隨地使用。總之，這款鋼筆是一個完美的結合了美學和實用性的產品，是您日常書寫的最佳選擇。\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "你是一個產品設計師。\n",
    "\n",
    "為我的鋼筆寫一個產品描述\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "筆尖流暢，書寫自如，讓你的字跳脫紙面！\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "你是一個產品設計師。\n",
    "\n",
    "Q:為我的餅乾寫一個產品描述\n",
    "A:脆香無比，餅乾饗宴！\n",
    "\n",
    "Q:為我的剪刀寫一個產品描述\n",
    "A:剪刀創新，尖端科技！\n",
    "\n",
    "Q:為我的手表寫一個產品描述\n",
    "A:手腕品味，與時間對話！\n",
    "\n",
    "Q:為我的鋼筆寫一個產品描述\n",
    "A:\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当你6岁时，你妹妹是5岁半。现在你70岁，经过64年，你妹妹现在应该是70-64+5.5=11.5岁。\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "当我6岁时，我的妹妹是我的一半年龄。现在我70岁了，我的妹妹多大？\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "当我6岁时，我的妹妹是3岁。\n",
      "现在我70岁，经过64年，我的妹妹现在应该是3+64=67岁。\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "当我6岁时，我的妹妹是我的一半年龄。现在我70岁了，我的妹妹多大？\n",
    "让我们逐步思考。\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes. Part of golf is trying to get a lower point total than others, which is achieved by completing each hole in as few strokes as possible.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "Part of golf is trying to get a higher point total than others. Yes or No?\n",
    "高尔夫球是一项运动，目标是将球打入尽可能少的杆数下的洞中。比赛通常由18个洞组成，每个洞都有一个特定的抛杆数，称为标准杆。球员需要使用不同的球杆，如马克思、铁杆和木杆，以尽可能少的杆数将球打入洞中。最终得分是所有洞的杆数之和，得分最低的球员获胜。\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "高尔夫球是一项运动，目标是将球打入尽可能少的杆数下的洞中。比赛通常由18个洞组成，每个洞都有一个特定的抛杆数，称为标准杆。球员需要使用不同的球杆，如马克思、铁杆和木杆，以尽可能少的杆数将球打入洞中。最终得分是所有洞的杆数之和。在比赛中，球员通常与其他球员竞争，试图获得比他们更高的得分。\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "输入：希腊比墨西哥大。\n",
    "知识：希腊的面积约为131,957平方公里，而墨西哥的面积约为1,964,375平方公里，使墨西哥比希腊大了1,389%。\n",
    "输入：眼镜总是会起雾。\n",
    "知识：当你的汗水、呼吸和周围的湿度中的水蒸气落在冷的表面上，冷却并变成微小的液滴时，会在眼镜镜片上产生冷凝。你看到的是一层薄膜。你的镜片相对于你的呼吸会比较凉，尤其是当外面的空气很冷时。\n",
    "输入：鱼有思考能力。\n",
    "知识：鱼比它们看起来更聪明。在许多领域，如记忆力，它们的认知能力与或超过非人类灵长类动物等“更高级”的脊椎动物。鱼的长期记忆帮助它们跟踪复杂的社交关系。\n",
    "输入：一个人一生中吸烟很多香烟的常见影响是患肺癌的几率高于正常水平。\n",
    "知识：那些一生中平均每天吸烟不到一支香烟的人，患肺癌的风险是从不吸烟者的9倍。在每天吸烟1到10支香烟之间的人群中，死于肺癌的风险几乎是从不吸烟者的12倍。\n",
    "输入：一块石头和一颗卵石大小相同。\n",
    "知识：卵石是一种根据Udden-Wentworth沉积学尺度的颗粒大小为4到64毫米的岩屑。卵石通常被认为比颗粒（直径2到4毫米）大，比卵石（直径64到256毫米）小。\n",
    "输入：高尔夫球的一部分是试图获得比其他人更高的得分。\n",
    "知识：\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "否。高尔夫球的目标是以最少的杆数打完一组洞，而不是试图获得比其他人更高的得分。在高尔夫球比赛中，每个杆计为一分，总杆数用于确定比赛的获胜者。因此，高尔夫球的一部分是试图以最少的杆数打完一组洞，而不是试图获得比其他人更高的得分。\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "问题：高尔夫球的一部分是试图获得比其他人更高的得分。是或否？\n",
    "知识：高尔夫球的目标是以最少的杆数打完一组洞。一轮高尔夫球比赛通常包括18个洞。每个洞在标准高尔夫球场上一轮只打一次。每个杆计为一分，总杆数用于确定比赛的获胜者。\n",
    "解释和答案： \n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "这是一个错误的陈述，因为任何奇数的和都是奇数，而不可能是偶数。\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "这组数字中的奇数加起来是一个偶数：17、9、10、12、13、4、2、8、7、16、19、17、21、11、15。\n",
    "A：\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "答案是True。\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"\n",
    "这组数字中的奇数加起来是一个偶数：4、8、9、15、12、2、1。\n",
    "A：答案是False。\n",
    "这组数字中的奇数加起来是一个偶数：17、10、19、4、8、12、24。\n",
    "A：答案是True。\n",
    "这组数字中的奇数加起来是一个偶数：16、11、14、4、8、13、24。\n",
    "A：答案是True。\n",
    "这组数字中的奇数加起来是一个偶数：17、9、10、12、13、4、2。\n",
    "A：答案是False。\n",
    "这组数字中的奇数加起来是一个偶数：15、32、5、13、82、7、1。\n",
    "A：\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import os\n",
    "from langchain.llms import OpenAI\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(model_name='text-davinci-003', temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Today is 27 February 2023. I was born exactly 25 years ago. What is the date I was born in MM/DD/YYYY?\"\n",
    " \n",
    "DATE_UNDERSTANDING_PROMPT = \"\"\"\n",
    "# Q: 2015 is coming in 36 hours. What is the date one week from today in MM/DD/YYYY?\n",
    "# If 2015 is coming in 36 hours, then today is 36 hours before.\n",
    "today = datetime(2015, 1, 1) - relativedelta(hours=36)\n",
    "# One week from today,\n",
    "one_week_from_today = today + relativedelta(weeks=1)\n",
    "# The answer formatted with %m/%d/%Y is\n",
    "one_week_from_today.strftime('%m/%d/%Y')\n",
    "# Q: The first day of 2019 is a Tuesday, and today is the first Monday of 2019. What is the date today in MM/DD/YYYY?\n",
    "# If the first day of 2019 is a Tuesday, and today is the first Monday of 2019, then today is 6 days later.\n",
    "today = datetime(2019, 1, 1) + relativedelta(days=6)\n",
    "# The answer formatted with %m/%d/%Y is\n",
    "today.strftime('%m/%d/%Y')\n",
    "# Q: The concert was scheduled to be on 06/01/1943, but was delayed by one day to today. What is the date 10 days ago in MM/DD/YYYY?\n",
    "# If the concert was scheduled to be on 06/01/1943, but was delayed by one day to today, then today is one day later.\n",
    "today = datetime(1943, 6, 1) + relativedelta(days=1)\n",
    "# 10 days ago,\n",
    "ten_days_ago = today - relativedelta(days=10)\n",
    "# The answer formatted with %m/%d/%Y is\n",
    "ten_days_ago.strftime('%m/%d/%Y')\n",
    "# Q: It is 4/19/1969 today. What is the date 24 hours later in MM/DD/YYYY?\n",
    "# It is 4/19/1969 today.\n",
    "today = datetime(1969, 4, 19)\n",
    "# 24 hours later,\n",
    "later = today + relativedelta(hours=24)\n",
    "# The answer formatted with %m/%d/%Y is\n",
    "today.strftime('%m/%d/%Y')\n",
    "# Q: Jane thought today is 3/11/2002, but today is in fact Mar 12, which is 1 day later. What is the date 24 hours later in MM/DD/YYYY?\n",
    "# If Jane thought today is 3/11/2002, but today is in fact Mar 12, then today is 3/1/2002.\n",
    "today = datetime(2002, 3, 12)\n",
    "# 24 hours later,\n",
    "later = today + relativedelta(hours=24)\n",
    "# The answer formatted with %m/%d/%Y is\n",
    "later.strftime('%m/%d/%Y')\n",
    "# Q: Jane was born on the last day of Feburary in 2001. Today is her 16-year-old birthday. What is the date yesterday in MM/DD/YYYY?\n",
    "# If Jane was born on the last day of Feburary in 2001 and today is her 16-year-old birthday, then today is 16 years later.\n",
    "today = datetime(2001, 2, 28) + relativedelta(years=16)\n",
    "# Yesterday,\n",
    "yesterday = today - relativedelta(days=1)\n",
    "# The answer formatted with %m/%d/%Y is\n",
    "yesterday.strftime('%m/%d/%Y')\n",
    "# Q: {question}\n",
    "\"\"\".strip() + '\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# If today is 27 February 2023 and I was born exactly 25 years ago, then I was born 25 years before.\n",
      "today = datetime(2023, 2, 27)\n",
      "# I was born 25 years before,\n",
      "born = today - relativedelta(years=25)\n",
      "# The answer formatted with %m/%d/%Y is\n",
      "born.strftime('%m/%d/%Y')\n"
     ]
    }
   ],
   "source": [
    "llm_out = llm(DATE_UNDERSTANDING_PROMPT.format(question=question))\n",
    "print(llm_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1998-02-27 00:00:00\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mygpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
